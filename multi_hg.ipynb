{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_lib\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', '.*output shape of zoom.*')\n",
    "import pickle\n",
    "import importlib\n",
    "importlib.reload(model_lib)\n",
    "\n",
    "import os\n",
    "import time\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config to train\n",
    "# TODO: check Config is correct\n",
    "class ProposalConfig():\n",
    "    NAME = \"InSegm\"\n",
    "    GPU_COUNT = 1\n",
    "    # online training\n",
    "    IMAGES_PER_GPU = 16\n",
    "    STEPS_PER_EPOCH = 100\n",
    "    NUM_WORKERS = 16\n",
    "    PIN_MEMORY = True\n",
    "    DATA_ORDER = \"cw_ins\"\n",
    "    VALIDATION_STEPS = 20\n",
    "    # including gt\n",
    "    NUM_CLASSES = 81\n",
    "    \n",
    "    # only flips\n",
    "    MEAN_PIXEL = np.array([0.485, 0.456, 0.406],dtype=np.float32).reshape(1,1,-1)\n",
    "    STD_PIXEL = np.array([0.229, 0.224, 0.225],dtype=np.float32).reshape(1,1,-1)\n",
    "    CLASS_NAMES = [\n",
    "        'BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "        'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign',\n",
    "        'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep',\n",
    "        'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella',\n",
    "        'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard',\n",
    "        'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "        'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork',\n",
    "        'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange',\n",
    "        'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair',\n",
    "        'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv',\n",
    "        'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave',\n",
    "        'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase',\n",
    "        'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "    ]\n",
    "    WIDTH = 224\n",
    "    HEIGHT = 224\n",
    "    CROP_SIZE = 224\n",
    "    def __init__(self):\n",
    "        self.BATCH_SIZE = self.IMAGES_PER_GPU * self.GPU_COUNT\n",
    "        self.IMAGE_SHAPE = (self.WIDTH, self.HEIGHT,3)\n",
    "\n",
    "    def display(self):\n",
    "        \"\"\"Display Configuration values.\"\"\"\n",
    "        print(\"\\nConfigurations:\")\n",
    "        for a in dir(self):\n",
    "            if not a.startswith(\"__\") and not callable(getattr(self, a)):\n",
    "                print(\"{:30} {}\".format(a, getattr(self, a)))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_dir = \"/media/Data1/interns/aravind/train2017/\"\n",
    "# train_image_dir = \"/media/Data1/interns/aravind/val2017/\"\n",
    "val_image_dir = \"/media/Data1/interns/aravind/val2017/\"\n",
    "config = ProposalConfig()\n",
    "model_dir = \"./models/\"\n",
    "train_pickle = \"/media/Data1/interns/aravind/re/data/train_cwid.pickle\"\n",
    "# train_pickle = \"/media/Data1/interns/aravind/re/data/val_cwid.pickle\"\n",
    "val_pickle = \"/media/Data1/interns/aravind/re/data/val_cwid.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_pickle,\"rb\") as train_ann:\n",
    "    train_cwid = pickle.load(train_ann)\n",
    "with open(val_pickle,\"rb\") as val_ann:\n",
    "    val_cwid = pickle.load(val_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = model_lib.get_loader(train_cwid,config,train_image_dir)\n",
    "val_loader = model_lib.get_loader(val_cwid,config,val_image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "net = model_lib.MultiHGModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.vgg0.load_state_dict(torch.load(\"./models/split_vgg16_features_1.pt\"))\n",
    "# net.vgg1.load_state_dict(torch.load(\"./models/split_vgg16_features_4.pt\"))\n",
    "pretrained_dict = torch.load(model_dir+\"bbox_01.pt\")\n",
    "net_dict = net.state_dict()\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in net_dict}\n",
    "\n",
    "net_dict.update(pretrained_dict) \n",
    "net.load_state_dict(net_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.vgg1.load_state_dict(net.vgg0.state_dict())\n",
    "# net.mp1.load_state_dict(net.mp0.state_dict())\n",
    "# net.vgg1.load_state_dict(torch.load(\"./models/split_vgg16_features_4.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_trainable(module,state):\n",
    "    for param in module.parameters():\n",
    "        param.requires_grad = state\n",
    "\n",
    "set_trainable(net,False)\n",
    "# set_trainable(net.mp0,True)\n",
    "# set_trainable(net.mp1,True)\n",
    "set_trainable(net.class_predictor,True)\n",
    "for name,child in net.vgg0.named_children():\n",
    "    if name[:-1] == \"layer\":\n",
    "        [set_trainable(s.ignore_filters,True) for s in child[::2]]\n",
    "        [set_trainable(s.copy_filters,True) for s in child[::2]]\n",
    "# for name,child in net.vgg1.named_children():\n",
    "#     if name[:-1] == \"layer\":\n",
    "#         [set_trainable(s.ignore_filters,False) for s in child[::2]]\n",
    "#         [set_trainable(s.copy_filters,False) for s in child[::2]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30135857 30135857\n",
      "[{'params': <generator object Module.parameters at 0x7fd43404a620>, 'lr': 0.001, 'momentum': 0.9}, {'params': <generator object Module.parameters at 0x7fd435c17518>, 'lr': 0.001, 'momentum': 0.9}, {'params': <generator object Module.parameters at 0x7fd435c174c0>, 'lr': 0.001, 'momentum': 0.9}, {'params': <generator object Module.parameters at 0x7fd435c17468>, 'lr': 0.001, 'momentum': 0.9}, {'params': <generator object Module.parameters at 0x7fd435c17410>, 'lr': 0.001, 'momentum': 0.9}, {'params': <generator object Module.parameters at 0x7fd435c17728>, 'lr': 0.001, 'momentum': 0.9}, {'params': <generator object Module.parameters at 0x7fd435c17780>, 'lr': 0.001, 'momentum': 0.9}, {'params': <generator object Module.parameters at 0x7fd435c177d8>, 'lr': 0.001, 'momentum': 0.9}, {'params': <generator object Module.parameters at 0x7fd435c17830>, 'lr': 0.001, 'momentum': 0.9}, {'params': <generator object Module.parameters at 0x7fd435c17888>, 'lr': 0.001, 'momentum': 0.9}, {'params': <generator object Module.parameters at 0x7fd435c178e0>, 'lr': 0.001, 'momentum': 0.9}, {'params': <generator object Module.parameters at 0x7fd435c17938>, 'lr': 0.001, 'momentum': 0.9}, {'params': <generator object Module.parameters at 0x7fd435c17990>, 'lr': 0.001, 'momentum': 0.9}, {'params': <generator object Module.parameters at 0x7fd435c179e8>, 'lr': 0.001, 'momentum': 0.9}, {'params': <generator object Module.parameters at 0x7fd435c17a40>, 'lr': 0.001, 'momentum': 0.9}, {'params': <generator object Module.parameters at 0x7fd435c17a98>, 'lr': 0.001, 'momentum': 0.9}, {'params': <generator object Module.parameters at 0x7fd435c17af0>, 'lr': 0.001, 'momentum': 0.9}, {'params': <generator object Module.parameters at 0x7fd435c17b48>, 'lr': 0.001, 'momentum': 0.9}, {'params': <generator object Module.parameters at 0x7fd435c17ba0>, 'lr': 0.001, 'momentum': 0.9}, {'params': <generator object Module.parameters at 0x7fd435c17bf8>, 'lr': 0.001, 'momentum': 0.9}, {'params': <generator object Module.parameters at 0x7fd435c17c50>, 'lr': 0.001, 'momentum': 0.9}, {'params': <generator object Module.parameters at 0x7fd435c17ca8>, 'lr': 0.001, 'momentum': 0.9}, {'params': <generator object Module.parameters at 0x7fd435c17d00>, 'lr': 0.001, 'momentum': 0.9}, {'params': <generator object Module.parameters at 0x7fd435c17d58>, 'lr': 0.001, 'momentum': 0.9}, {'params': <generator object Module.parameters at 0x7fd435c17db0>, 'lr': 0.001, 'momentum': 0.9}, {'params': <generator object Module.parameters at 0x7fd435c17e08>, 'lr': 0.001, 'momentum': 0.9}, {'params': <generator object Module.parameters at 0x7fd435c17e60>, 'lr': 0.001, 'momentum': 0.9}]\n"
     ]
    }
   ],
   "source": [
    "# optimizer = optim.Adam(filter(lambda p: p.requires_grad, net.parameters()),lr = 0.001)\n",
    "# optimizer = optim.SGD(filter(lambda p: p.requires_grad, net.parameters()), lr=0.01, momentum=0.9)\n",
    "param_lr = []\n",
    "# param_lr.append({'params': net.mp0.parameters(),'lr':1e-2,'momentum':0.9})\n",
    "# param_lr.append({'params': net.mp1.parameters(),'lr':1e-2,'momentum':0.9})\n",
    "param_lr.append({'params': net.class_predictor.parameters(),'lr':1e-3,'momentum':0.9})\n",
    "\n",
    "for name,child in net.vgg0.named_children():\n",
    "    if name[:-1] == \"layer\":\n",
    "        for s in child[::2]:\n",
    "            lr = 0\n",
    "            if int(name[-1]) > 0:\n",
    "                lr = 1e-3\n",
    "            else:\n",
    "                lr = 0\n",
    "            param_lr.append({'params':s.ignore_filters.parameters(),'lr':lr,'momentum':0.9})\n",
    "            param_lr.append({'params':s.copy_filters.parameters(),'lr':1e-3,'momentum':0.9})\n",
    "# for name,child in net.vgg1.named_children():\n",
    "#     if name[:-1] == \"layer\":\n",
    "#         for s in child[::2]:\n",
    "#             lr = 0\n",
    "#             if int(name[-1]) > 0:\n",
    "#                 lr = 0\n",
    "#             else:\n",
    "#                 lr = 0\n",
    "#             param_lr.append({'params':s.ignore_filters.parameters(),'lr':lr,'momentum':0.9})\n",
    "#             param_lr.append({'params':s.copy_filters.parameters(),'lr':1e-3,'momentum':0.9})\n",
    "\n",
    "net_size = sum([i.numel() for i in net.parameters()])\n",
    "trainable_params = filter(lambda p: p.requires_grad, net.parameters())\n",
    "trainable_size = sum([i.numel() for i in trainable_params])\n",
    "print(net_size,trainable_size)\n",
    "print(param_lr)\n",
    "optimizer = optim.SGD(param_lr)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=1, patience=10, verbose=True, threshold=0.0001, threshold_mode='rel', cooldown=100, min_lr=1e-2, eps=1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = nn.DataParallel(net)\n",
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch:  59 epoch:  0 loss: 1.63183\n",
      "class_loss: 1.63183 \t mask_loss: 1.63183\n",
      "class_acc: 0.57188 \t mask_acc: 0.57188\n",
      "batch:  119 epoch:  0 loss: 1.53174\n",
      "class_loss: 1.53174 \t mask_loss: 1.53174\n",
      "class_acc: 0.57500 \t mask_acc: 0.57500\n",
      "batch:  179 epoch:  0 loss: 1.45613\n",
      "class_loss: 1.45613 \t mask_loss: 1.45613\n",
      "class_acc: 0.59375 \t mask_acc: 0.59375\n",
      "batch:  239 epoch:  0 loss: 1.39448\n",
      "class_loss: 1.39448 \t mask_loss: 1.39448\n",
      "class_acc: 0.60729 \t mask_acc: 0.60729\n",
      "batch:  299 epoch:  0 loss: 1.47583\n",
      "class_loss: 1.47583 \t mask_loss: 1.47583\n",
      "class_acc: 0.59583 \t mask_acc: 0.59583\n",
      "batch:  359 epoch:  0 loss: 1.60552\n",
      "class_loss: 1.60552 \t mask_loss: 1.60552\n",
      "class_acc: 0.55833 \t mask_acc: 0.55833\n",
      "batch:  419 epoch:  0 loss: 1.47130\n",
      "class_loss: 1.47130 \t mask_loss: 1.47130\n",
      "class_acc: 0.58854 \t mask_acc: 0.58854\n",
      "batch:  479 epoch:  0 loss: 1.55222\n",
      "class_loss: 1.55222 \t mask_loss: 1.55222\n",
      "class_acc: 0.56979 \t mask_acc: 0.56979\n",
      "batch:  539 epoch:  0 loss: 1.43657\n",
      "class_loss: 1.43657 \t mask_loss: 1.43657\n",
      "class_acc: 0.61146 \t mask_acc: 0.61146\n",
      "batch:  599 epoch:  0 loss: 1.43644\n",
      "class_loss: 1.43644 \t mask_loss: 1.43644\n",
      "class_acc: 0.60104 \t mask_acc: 0.60104\n",
      "batch:  659 epoch:  0 loss: 1.39190\n",
      "class_loss: 1.39190 \t mask_loss: 1.39190\n",
      "class_acc: 0.61562 \t mask_acc: 0.61562\n",
      "batch:  719 epoch:  0 loss: 1.52601\n",
      "class_loss: 1.52601 \t mask_loss: 1.52601\n",
      "class_acc: 0.58854 \t mask_acc: 0.58854\n",
      "batch:  779 epoch:  0 loss: 1.47828\n",
      "class_loss: 1.47828 \t mask_loss: 1.47828\n",
      "class_acc: 0.58437 \t mask_acc: 0.58437\n",
      "batch:  839 epoch:  0 loss: 1.52445\n",
      "class_loss: 1.52445 \t mask_loss: 1.52445\n",
      "class_acc: 0.56250 \t mask_acc: 0.56250\n",
      "batch:  899 epoch:  0 loss: 1.37867\n",
      "class_loss: 1.37867 \t mask_loss: 1.37867\n",
      "class_acc: 0.61042 \t mask_acc: 0.61042\n",
      "batch:  959 epoch:  0 loss: 1.41181\n",
      "class_loss: 1.41181 \t mask_loss: 1.41181\n",
      "class_acc: 0.60417 \t mask_acc: 0.60417\n",
      "batch:  1019 epoch:  0 loss: 1.46993\n",
      "class_loss: 1.46993 \t mask_loss: 1.46993\n",
      "class_acc: 0.60000 \t mask_acc: 0.60000\n",
      "batch:  1079 epoch:  0 loss: 1.41096\n",
      "class_loss: 1.41096 \t mask_loss: 1.41096\n",
      "class_acc: 0.61146 \t mask_acc: 0.61146\n",
      "batch:  1139 epoch:  0 loss: 1.52137\n",
      "class_loss: 1.52137 \t mask_loss: 1.52137\n",
      "class_acc: 0.56458 \t mask_acc: 0.56458\n",
      "batch:  1199 epoch:  0 loss: 1.52542\n",
      "class_loss: 1.52542 \t mask_loss: 1.52542\n",
      "class_acc: 0.59375 \t mask_acc: 0.59375\n",
      "batch:  1259 epoch:  0 loss: 1.52263\n",
      "class_loss: 1.52263 \t mask_loss: 1.52263\n",
      "class_acc: 0.59375 \t mask_acc: 0.59375\n",
      "batch:  1319 epoch:  0 loss: 1.48379\n",
      "class_loss: 1.48379 \t mask_loss: 1.48379\n",
      "class_acc: 0.60833 \t mask_acc: 0.60833\n",
      "batch:  1379 epoch:  0 loss: 1.33697\n",
      "class_loss: 1.33697 \t mask_loss: 1.33697\n",
      "class_acc: 0.61979 \t mask_acc: 0.61979\n",
      "batch:  1439 epoch:  0 loss: 1.42898\n",
      "class_loss: 1.42898 \t mask_loss: 1.42898\n",
      "class_acc: 0.61875 \t mask_acc: 0.61875\n",
      "batch:  1499 epoch:  0 loss: 1.37322\n",
      "class_loss: 1.37322 \t mask_loss: 1.37322\n",
      "class_acc: 0.61979 \t mask_acc: 0.61979\n",
      "batch:  1559 epoch:  0 loss: 1.34797\n",
      "class_loss: 1.34797 \t mask_loss: 1.34797\n",
      "class_acc: 0.64167 \t mask_acc: 0.64167\n",
      "batch:  1619 epoch:  0 loss: 1.39021\n",
      "class_loss: 1.39021 \t mask_loss: 1.39021\n",
      "class_acc: 0.61667 \t mask_acc: 0.61667\n",
      "batch:  1679 epoch:  0 loss: 1.43668\n",
      "class_loss: 1.43668 \t mask_loss: 1.43668\n",
      "class_acc: 0.60729 \t mask_acc: 0.60729\n",
      "batch:  1739 epoch:  0 loss: 1.36206\n",
      "class_loss: 1.36206 \t mask_loss: 1.36206\n",
      "class_acc: 0.62813 \t mask_acc: 0.62813\n",
      "batch:  1799 epoch:  0 loss: 1.38621\n",
      "class_loss: 1.38621 \t mask_loss: 1.38621\n",
      "class_acc: 0.60625 \t mask_acc: 0.60625\n",
      "batch:  1859 epoch:  0 loss: 1.43533\n",
      "class_loss: 1.43533 \t mask_loss: 1.43533\n",
      "class_acc: 0.60729 \t mask_acc: 0.60729\n",
      "batch:  1919 epoch:  0 loss: 1.31810\n",
      "class_loss: 1.31810 \t mask_loss: 1.31810\n",
      "class_acc: 0.64583 \t mask_acc: 0.64583\n",
      "batch:  1979 epoch:  0 loss: 1.33363\n",
      "class_loss: 1.33363 \t mask_loss: 1.33363\n",
      "class_acc: 0.63333 \t mask_acc: 0.63333\n",
      "batch:  2039 epoch:  0 loss: 1.30315\n",
      "class_loss: 1.30315 \t mask_loss: 1.30315\n",
      "class_acc: 0.63542 \t mask_acc: 0.63542\n",
      "batch:  2099 epoch:  0 loss: 1.36106\n",
      "class_loss: 1.36106 \t mask_loss: 1.36106\n",
      "class_acc: 0.62292 \t mask_acc: 0.62292\n",
      "batch:  2159 epoch:  0 loss: 1.29885\n",
      "class_loss: 1.29885 \t mask_loss: 1.29885\n",
      "class_acc: 0.63854 \t mask_acc: 0.63854\n",
      "batch:  2219 epoch:  0 loss: 1.34815\n",
      "class_loss: 1.34815 \t mask_loss: 1.34815\n",
      "class_acc: 0.63542 \t mask_acc: 0.63542\n",
      "batch:  2279 epoch:  0 loss: 1.35576\n",
      "class_loss: 1.35576 \t mask_loss: 1.35576\n",
      "class_acc: 0.63333 \t mask_acc: 0.63333\n",
      "batch:  2339 epoch:  0 loss: 1.37629\n",
      "class_loss: 1.37629 \t mask_loss: 1.37629\n",
      "class_acc: 0.62292 \t mask_acc: 0.62292\n",
      "batch:  2399 epoch:  0 loss: 1.27756\n",
      "class_loss: 1.27756 \t mask_loss: 1.27756\n",
      "class_acc: 0.62604 \t mask_acc: 0.62604\n",
      "batch:  2459 epoch:  0 loss: 1.24902\n",
      "class_loss: 1.24902 \t mask_loss: 1.24902\n",
      "class_acc: 0.65833 \t mask_acc: 0.65833\n",
      "batch:  2519 epoch:  0 loss: 1.21818\n",
      "class_loss: 1.21818 \t mask_loss: 1.21818\n",
      "class_acc: 0.65729 \t mask_acc: 0.65729\n",
      "batch:  2579 epoch:  0 loss: 1.21265\n",
      "class_loss: 1.21265 \t mask_loss: 1.21265\n",
      "class_acc: 0.65625 \t mask_acc: 0.65625\n",
      "batch:  2639 epoch:  0 loss: 1.21084\n",
      "class_loss: 1.21084 \t mask_loss: 1.21084\n",
      "class_acc: 0.65625 \t mask_acc: 0.65625\n",
      "batch:  2699 epoch:  0 loss: 1.21723\n",
      "class_loss: 1.21723 \t mask_loss: 1.21723\n",
      "class_acc: 0.65417 \t mask_acc: 0.65417\n",
      "batch:  2759 epoch:  0 loss: 1.29386\n",
      "class_loss: 1.29386 \t mask_loss: 1.29386\n",
      "class_acc: 0.63333 \t mask_acc: 0.63333\n",
      "batch:  2819 epoch:  0 loss: 1.24106\n",
      "class_loss: 1.24106 \t mask_loss: 1.24106\n",
      "class_acc: 0.63750 \t mask_acc: 0.63750\n",
      "batch:  2879 epoch:  0 loss: 1.27219\n",
      "class_loss: 1.27219 \t mask_loss: 1.27219\n",
      "class_acc: 0.63854 \t mask_acc: 0.63854\n",
      "batch:  2939 epoch:  0 loss: 1.29693\n",
      "class_loss: 1.29693 \t mask_loss: 1.29693\n",
      "class_acc: 0.64375 \t mask_acc: 0.64375\n",
      "batch:  2999 epoch:  0 loss: 1.32278\n",
      "class_loss: 1.32278 \t mask_loss: 1.32278\n",
      "class_acc: 0.62708 \t mask_acc: 0.62708\n",
      "batch:  3059 epoch:  0 loss: 1.17587\n",
      "class_loss: 1.17587 \t mask_loss: 1.17587\n",
      "class_acc: 0.66042 \t mask_acc: 0.66042\n",
      "batch:  3119 epoch:  0 loss: 1.33136\n",
      "class_loss: 1.33136 \t mask_loss: 1.33136\n",
      "class_acc: 0.62813 \t mask_acc: 0.62813\n",
      "batch:  3179 epoch:  0 loss: 1.34634\n",
      "class_loss: 1.34634 \t mask_loss: 1.34634\n",
      "class_acc: 0.61458 \t mask_acc: 0.61458\n",
      "batch:  3239 epoch:  0 loss: 1.24780\n",
      "class_loss: 1.24780 \t mask_loss: 1.24780\n",
      "class_acc: 0.64687 \t mask_acc: 0.64687\n",
      "batch:  3299 epoch:  0 loss: 1.29454\n",
      "class_loss: 1.29454 \t mask_loss: 1.29454\n",
      "class_acc: 0.64271 \t mask_acc: 0.64271\n",
      "batch:  3359 epoch:  0 loss: 1.37814\n",
      "class_loss: 1.37814 \t mask_loss: 1.37814\n",
      "class_acc: 0.61562 \t mask_acc: 0.61562\n",
      "batch:  3419 epoch:  0 loss: 1.29828\n",
      "class_loss: 1.29828 \t mask_loss: 1.29828\n",
      "class_acc: 0.63542 \t mask_acc: 0.63542\n",
      "batch:  3479 epoch:  0 loss: 1.26709\n",
      "class_loss: 1.26709 \t mask_loss: 1.26709\n",
      "class_acc: 0.64375 \t mask_acc: 0.64375\n",
      "batch:  3539 epoch:  0 loss: 1.26465\n",
      "class_loss: 1.26465 \t mask_loss: 1.26465\n",
      "class_acc: 0.65000 \t mask_acc: 0.65000\n",
      "batch:  3599 epoch:  0 loss: 1.14500\n",
      "class_loss: 1.14500 \t mask_loss: 1.14500\n",
      "class_acc: 0.68542 \t mask_acc: 0.68542\n",
      "batch:  3659 epoch:  0 loss: 1.35195\n",
      "class_loss: 1.35195 \t mask_loss: 1.35195\n",
      "class_acc: 0.62083 \t mask_acc: 0.62083\n",
      "batch:  3719 epoch:  0 loss: 1.19301\n",
      "class_loss: 1.19301 \t mask_loss: 1.19301\n",
      "class_acc: 0.65104 \t mask_acc: 0.65104\n",
      "batch:  3779 epoch:  0 loss: 1.17462\n",
      "class_loss: 1.17462 \t mask_loss: 1.17462\n",
      "class_acc: 0.66042 \t mask_acc: 0.66042\n",
      "batch:  3839 epoch:  0 loss: 1.22901\n",
      "class_loss: 1.22901 \t mask_loss: 1.22901\n",
      "class_acc: 0.65000 \t mask_acc: 0.65000\n",
      "batch:  3899 epoch:  0 loss: 1.21515\n",
      "class_loss: 1.21515 \t mask_loss: 1.21515\n",
      "class_acc: 0.65625 \t mask_acc: 0.65625\n",
      "batch:  3959 epoch:  0 loss: 1.14375\n",
      "class_loss: 1.14375 \t mask_loss: 1.14375\n",
      "class_acc: 0.67188 \t mask_acc: 0.67188\n",
      "batch:  4019 epoch:  0 loss: 1.24050\n",
      "class_loss: 1.24050 \t mask_loss: 1.24050\n",
      "class_acc: 0.65729 \t mask_acc: 0.65729\n",
      "batch:  4079 epoch:  0 loss: 1.30208\n",
      "class_loss: 1.30208 \t mask_loss: 1.30208\n",
      "class_acc: 0.65417 \t mask_acc: 0.65417\n",
      "batch:  4139 epoch:  0 loss: 1.17973\n",
      "class_loss: 1.17973 \t mask_loss: 1.17973\n",
      "class_acc: 0.68229 \t mask_acc: 0.68229\n",
      "batch:  4199 epoch:  0 loss: 1.22392\n",
      "class_loss: 1.22392 \t mask_loss: 1.22392\n",
      "class_acc: 0.66250 \t mask_acc: 0.66250\n",
      "batch:  4259 epoch:  0 loss: 1.18993\n",
      "class_loss: 1.18993 \t mask_loss: 1.18993\n",
      "class_acc: 0.67292 \t mask_acc: 0.67292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch:  4319 epoch:  0 loss: 1.19826\n",
      "class_loss: 1.19826 \t mask_loss: 1.19826\n",
      "class_acc: 0.68333 \t mask_acc: 0.68333\n",
      "batch:  4379 epoch:  0 loss: 1.17539\n",
      "class_loss: 1.17539 \t mask_loss: 1.17539\n",
      "class_acc: 0.66563 \t mask_acc: 0.66563\n",
      "batch:  4439 epoch:  0 loss: 1.18518\n",
      "class_loss: 1.18518 \t mask_loss: 1.18518\n",
      "class_acc: 0.67708 \t mask_acc: 0.67708\n",
      "batch:  4499 epoch:  0 loss: 1.17123\n",
      "class_loss: 1.17123 \t mask_loss: 1.17123\n",
      "class_acc: 0.66667 \t mask_acc: 0.66667\n",
      "batch:  4559 epoch:  0 loss: 1.19831\n",
      "class_loss: 1.19831 \t mask_loss: 1.19831\n",
      "class_acc: 0.65833 \t mask_acc: 0.65833\n",
      "batch:  4619 epoch:  0 loss: 1.23574\n",
      "class_loss: 1.23574 \t mask_loss: 1.23574\n",
      "class_acc: 0.64792 \t mask_acc: 0.64792\n",
      "batch:  4679 epoch:  0 loss: 1.16881\n",
      "class_loss: 1.16881 \t mask_loss: 1.16881\n",
      "class_acc: 0.67188 \t mask_acc: 0.67188\n",
      "batch:  4739 epoch:  0 loss: 1.14067\n",
      "class_loss: 1.14067 \t mask_loss: 1.14067\n",
      "class_acc: 0.68854 \t mask_acc: 0.68854\n",
      "batch:  4799 epoch:  0 loss: 1.13895\n",
      "class_loss: 1.13895 \t mask_loss: 1.13895\n",
      "class_acc: 0.68125 \t mask_acc: 0.68125\n",
      "batch:  4859 epoch:  0 loss: 1.09330\n",
      "class_loss: 1.09330 \t mask_loss: 1.09330\n",
      "class_acc: 0.68125 \t mask_acc: 0.68125\n",
      "batch:  4919 epoch:  0 loss: 1.11525\n",
      "class_loss: 1.11525 \t mask_loss: 1.11525\n",
      "class_acc: 0.68646 \t mask_acc: 0.68646\n",
      "batch:  4979 epoch:  0 loss: 1.11216\n",
      "class_loss: 1.11216 \t mask_loss: 1.11216\n",
      "class_acc: 0.70208 \t mask_acc: 0.70208\n",
      "batch:  5039 epoch:  0 loss: 1.09631\n",
      "class_loss: 1.09631 \t mask_loss: 1.09631\n",
      "class_acc: 0.67188 \t mask_acc: 0.67188\n",
      "batch:  5099 epoch:  0 loss: 1.14723\n",
      "class_loss: 1.14723 \t mask_loss: 1.14723\n",
      "class_acc: 0.66563 \t mask_acc: 0.66563\n",
      "batch:  5159 epoch:  0 loss: 1.16804\n",
      "class_loss: 1.16804 \t mask_loss: 1.16804\n",
      "class_acc: 0.66563 \t mask_acc: 0.66563\n",
      "batch:  5219 epoch:  0 loss: 1.18707\n",
      "class_loss: 1.18707 \t mask_loss: 1.18707\n",
      "class_acc: 0.66979 \t mask_acc: 0.66979\n",
      "batch:  5279 epoch:  0 loss: 1.16906\n",
      "class_loss: 1.16906 \t mask_loss: 1.16906\n",
      "class_acc: 0.67396 \t mask_acc: 0.67396\n",
      "batch:  5339 epoch:  0 loss: 1.02693\n",
      "class_loss: 1.02693 \t mask_loss: 1.02693\n",
      "class_acc: 0.70833 \t mask_acc: 0.70833\n",
      "batch:  5399 epoch:  0 loss: 1.09228\n",
      "class_loss: 1.09228 \t mask_loss: 1.09228\n",
      "class_acc: 0.70312 \t mask_acc: 0.70312\n",
      "batch:  5459 epoch:  0 loss: 1.11345\n",
      "class_loss: 1.11345 \t mask_loss: 1.11345\n",
      "class_acc: 0.68125 \t mask_acc: 0.68125\n",
      "batch:  5519 epoch:  0 loss: 1.11556\n",
      "class_loss: 1.11556 \t mask_loss: 1.11556\n",
      "class_acc: 0.70000 \t mask_acc: 0.70000\n",
      "batch:  5579 epoch:  0 loss: 1.16185\n",
      "class_loss: 1.16185 \t mask_loss: 1.16185\n",
      "class_acc: 0.68333 \t mask_acc: 0.68333\n",
      "batch:  5639 epoch:  0 loss: 1.03555\n",
      "class_loss: 1.03555 \t mask_loss: 1.03555\n",
      "class_acc: 0.71771 \t mask_acc: 0.71771\n",
      "batch:  5699 epoch:  0 loss: 1.13553\n",
      "class_loss: 1.13553 \t mask_loss: 1.13553\n",
      "class_acc: 0.68750 \t mask_acc: 0.68750\n",
      "batch:  5759 epoch:  0 loss: 1.10544\n",
      "class_loss: 1.10544 \t mask_loss: 1.10544\n",
      "class_acc: 0.67708 \t mask_acc: 0.67708\n",
      "batch:  5819 epoch:  0 loss: 1.20057\n",
      "class_loss: 1.20057 \t mask_loss: 1.20057\n",
      "class_acc: 0.65104 \t mask_acc: 0.65104\n",
      "batch:  5879 epoch:  0 loss: 1.01629\n",
      "class_loss: 1.01629 \t mask_loss: 1.01629\n",
      "class_acc: 0.69063 \t mask_acc: 0.69063\n",
      "batch:  5939 epoch:  0 loss: 1.17511\n",
      "class_loss: 1.17511 \t mask_loss: 1.17511\n",
      "class_acc: 0.65625 \t mask_acc: 0.65625\n",
      "batch:  5999 epoch:  0 loss: 1.06165\n",
      "class_loss: 1.06165 \t mask_loss: 1.06165\n",
      "class_acc: 0.69896 \t mask_acc: 0.69896\n",
      "batch:  6059 epoch:  0 loss: 1.02821\n",
      "class_loss: 1.02821 \t mask_loss: 1.02821\n",
      "class_acc: 0.71354 \t mask_acc: 0.71354\n",
      "batch:  6119 epoch:  0 loss: 1.07739\n",
      "class_loss: 1.07739 \t mask_loss: 1.07739\n",
      "class_acc: 0.68750 \t mask_acc: 0.68750\n",
      "batch:  6179 epoch:  0 loss: 1.09375\n",
      "class_loss: 1.09375 \t mask_loss: 1.09375\n",
      "class_acc: 0.69792 \t mask_acc: 0.69792\n",
      "batch:  6239 epoch:  0 loss: 1.16627\n",
      "class_loss: 1.16627 \t mask_loss: 1.16627\n",
      "class_acc: 0.66354 \t mask_acc: 0.66354\n",
      "batch:  6299 epoch:  0 loss: 1.07689\n",
      "class_loss: 1.07689 \t mask_loss: 1.07689\n",
      "class_acc: 0.68333 \t mask_acc: 0.68333\n",
      "batch:  6359 epoch:  0 loss: 1.00052\n",
      "class_loss: 1.00052 \t mask_loss: 1.00052\n",
      "class_acc: 0.70521 \t mask_acc: 0.70521\n",
      "batch:  6419 epoch:  0 loss: 1.01691\n",
      "class_loss: 1.01691 \t mask_loss: 1.01691\n",
      "class_acc: 0.72604 \t mask_acc: 0.72604\n",
      "batch:  6479 epoch:  0 loss: 1.03958\n",
      "class_loss: 1.03958 \t mask_loss: 1.03958\n",
      "class_acc: 0.69896 \t mask_acc: 0.69896\n",
      "batch:  6539 epoch:  0 loss: 1.06277\n",
      "class_loss: 1.06277 \t mask_loss: 1.06277\n",
      "class_acc: 0.68958 \t mask_acc: 0.68958\n",
      "batch:  6599 epoch:  0 loss: 1.14050\n",
      "class_loss: 1.14050 \t mask_loss: 1.14050\n",
      "class_acc: 0.68437 \t mask_acc: 0.68437\n",
      "batch:  6659 epoch:  0 loss: 1.09295\n",
      "class_loss: 1.09295 \t mask_loss: 1.09295\n",
      "class_acc: 0.69583 \t mask_acc: 0.69583\n",
      "batch:  6719 epoch:  0 loss: 1.06371\n",
      "class_loss: 1.06371 \t mask_loss: 1.06371\n",
      "class_acc: 0.70417 \t mask_acc: 0.70417\n",
      "batch:  6779 epoch:  0 loss: 1.11094\n",
      "class_loss: 1.11094 \t mask_loss: 1.11094\n",
      "class_acc: 0.69688 \t mask_acc: 0.69688\n",
      "batch:  6839 epoch:  0 loss: 1.16863\n",
      "class_loss: 1.16863 \t mask_loss: 1.16863\n",
      "class_acc: 0.65833 \t mask_acc: 0.65833\n",
      "batch:  6899 epoch:  0 loss: 1.06824\n",
      "class_loss: 1.06824 \t mask_loss: 1.06824\n",
      "class_acc: 0.70208 \t mask_acc: 0.70208\n",
      "batch:  6959 epoch:  0 loss: 1.03638\n",
      "class_loss: 1.03638 \t mask_loss: 1.03638\n",
      "class_acc: 0.70312 \t mask_acc: 0.70312\n",
      "batch:  7019 epoch:  0 loss: 1.06274\n",
      "class_loss: 1.06274 \t mask_loss: 1.06274\n",
      "class_acc: 0.70208 \t mask_acc: 0.70208\n",
      "batch:  7079 epoch:  0 loss: 1.11877\n",
      "class_loss: 1.11877 \t mask_loss: 1.11877\n",
      "class_acc: 0.68646 \t mask_acc: 0.68646\n",
      "batch:  7139 epoch:  0 loss: 1.13699\n",
      "class_loss: 1.13699 \t mask_loss: 1.13699\n",
      "class_acc: 0.70312 \t mask_acc: 0.70312\n",
      "batch:  7199 epoch:  0 loss: 1.09158\n",
      "class_loss: 1.09158 \t mask_loss: 1.09158\n",
      "class_acc: 0.68854 \t mask_acc: 0.68854\n",
      "batch:  7259 epoch:  0 loss: 1.00786\n",
      "class_loss: 1.00786 \t mask_loss: 1.00786\n",
      "class_acc: 0.71771 \t mask_acc: 0.71771\n",
      "batch:  7319 epoch:  0 loss: 1.03463\n",
      "class_loss: 1.03463 \t mask_loss: 1.03463\n",
      "class_acc: 0.69583 \t mask_acc: 0.69583\n",
      "batch:  7379 epoch:  0 loss: 1.08541\n",
      "class_loss: 1.08541 \t mask_loss: 1.08541\n",
      "class_acc: 0.68958 \t mask_acc: 0.68958\n",
      "batch:  7439 epoch:  0 loss: 1.10496\n",
      "class_loss: 1.10496 \t mask_loss: 1.10496\n",
      "class_acc: 0.70729 \t mask_acc: 0.70729\n",
      "batch:  7499 epoch:  0 loss: 1.04891\n",
      "class_loss: 1.04891 \t mask_loss: 1.04891\n",
      "class_acc: 0.71042 \t mask_acc: 0.71042\n",
      "batch:  7559 epoch:  0 loss: 1.03233\n",
      "class_loss: 1.03233 \t mask_loss: 1.03233\n",
      "class_acc: 0.71146 \t mask_acc: 0.71146\n",
      "batch:  7619 epoch:  0 loss: 1.09176\n",
      "class_loss: 1.09176 \t mask_loss: 1.09176\n",
      "class_acc: 0.70208 \t mask_acc: 0.70208\n",
      "batch:  7679 epoch:  0 loss: 1.00770\n",
      "class_loss: 1.00770 \t mask_loss: 1.00770\n",
      "class_acc: 0.68750 \t mask_acc: 0.68750\n",
      "batch:  7739 epoch:  0 loss: 0.98553\n",
      "class_loss: 0.98553 \t mask_loss: 0.98553\n",
      "class_acc: 0.71875 \t mask_acc: 0.71875\n",
      "batch:  7799 epoch:  0 loss: 1.02987\n",
      "class_loss: 1.02987 \t mask_loss: 1.02987\n",
      "class_acc: 0.70625 \t mask_acc: 0.70625\n",
      "batch:  7859 epoch:  0 loss: 1.05299\n",
      "class_loss: 1.05299 \t mask_loss: 1.05299\n",
      "class_acc: 0.70729 \t mask_acc: 0.70729\n",
      "batch:  7919 epoch:  0 loss: 0.98875\n",
      "class_loss: 0.98875 \t mask_loss: 0.98875\n",
      "class_acc: 0.72292 \t mask_acc: 0.72292\n",
      "batch:  7979 epoch:  0 loss: 1.05643\n",
      "class_loss: 1.05643 \t mask_loss: 1.05643\n",
      "class_acc: 0.70625 \t mask_acc: 0.70625\n",
      "batch:  8039 epoch:  0 loss: 0.98847\n",
      "class_loss: 0.98847 \t mask_loss: 0.98847\n",
      "class_acc: 0.70729 \t mask_acc: 0.70729\n",
      "batch:  8099 epoch:  0 loss: 1.00604\n",
      "class_loss: 1.00604 \t mask_loss: 1.00604\n",
      "class_acc: 0.71562 \t mask_acc: 0.71562\n",
      "batch:  8159 epoch:  0 loss: 1.00721\n",
      "class_loss: 1.00721 \t mask_loss: 1.00721\n",
      "class_acc: 0.70104 \t mask_acc: 0.70104\n",
      "batch:  8219 epoch:  0 loss: 1.04730\n",
      "class_loss: 1.04730 \t mask_loss: 1.04730\n",
      "class_acc: 0.71250 \t mask_acc: 0.71250\n",
      "batch:  8279 epoch:  0 loss: 1.08223\n",
      "class_loss: 1.08223 \t mask_loss: 1.08223\n",
      "class_acc: 0.69583 \t mask_acc: 0.69583\n",
      "batch:  8339 epoch:  0 loss: 1.06383\n",
      "class_loss: 1.06383 \t mask_loss: 1.06383\n",
      "class_acc: 0.69167 \t mask_acc: 0.69167\n",
      "batch:  8399 epoch:  0 loss: 0.99855\n",
      "class_loss: 0.99855 \t mask_loss: 0.99855\n",
      "class_acc: 0.71458 \t mask_acc: 0.71458\n",
      "batch:  8459 epoch:  0 loss: 0.99803\n",
      "class_loss: 0.99803 \t mask_loss: 0.99803\n",
      "class_acc: 0.71562 \t mask_acc: 0.71562\n",
      "batch:  8519 epoch:  0 loss: 0.93434\n",
      "class_loss: 0.93434 \t mask_loss: 0.93434\n",
      "class_acc: 0.74062 \t mask_acc: 0.74062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch:  8579 epoch:  0 loss: 0.91158\n",
      "class_loss: 0.91158 \t mask_loss: 0.91158\n",
      "class_acc: 0.74479 \t mask_acc: 0.74479\n",
      "batch:  8639 epoch:  0 loss: 1.05951\n",
      "class_loss: 1.05951 \t mask_loss: 1.05951\n",
      "class_acc: 0.71562 \t mask_acc: 0.71562\n",
      "batch:  8699 epoch:  0 loss: 0.97307\n",
      "class_loss: 0.97307 \t mask_loss: 0.97307\n",
      "class_acc: 0.71562 \t mask_acc: 0.71562\n",
      "batch:  8759 epoch:  0 loss: 1.02031\n",
      "class_loss: 1.02031 \t mask_loss: 1.02031\n",
      "class_acc: 0.71250 \t mask_acc: 0.71250\n",
      "batch:  8819 epoch:  0 loss: 1.05960\n",
      "class_loss: 1.05960 \t mask_loss: 1.05960\n",
      "class_acc: 0.68542 \t mask_acc: 0.68542\n",
      "batch:  8879 epoch:  0 loss: 0.97111\n",
      "class_loss: 0.97111 \t mask_loss: 0.97111\n",
      "class_acc: 0.72188 \t mask_acc: 0.72188\n",
      "batch:  8939 epoch:  0 loss: 1.01226\n",
      "class_loss: 1.01226 \t mask_loss: 1.01226\n",
      "class_acc: 0.72083 \t mask_acc: 0.72083\n",
      "batch:  8999 epoch:  0 loss: 0.96983\n",
      "class_loss: 0.96983 \t mask_loss: 0.96983\n",
      "class_acc: 0.72500 \t mask_acc: 0.72500\n",
      "batch:  9059 epoch:  0 loss: 0.98380\n",
      "class_loss: 0.98380 \t mask_loss: 0.98380\n",
      "class_acc: 0.72396 \t mask_acc: 0.72396\n",
      "batch:  9119 epoch:  0 loss: 0.92519\n",
      "class_loss: 0.92519 \t mask_loss: 0.92519\n",
      "class_acc: 0.73333 \t mask_acc: 0.73333\n",
      "batch:  9179 epoch:  0 loss: 1.06298\n",
      "class_loss: 1.06298 \t mask_loss: 1.06298\n",
      "class_acc: 0.70833 \t mask_acc: 0.70833\n",
      "batch:  9239 epoch:  0 loss: 0.98524\n",
      "class_loss: 0.98524 \t mask_loss: 0.98524\n",
      "class_acc: 0.70833 \t mask_acc: 0.70833\n",
      "batch:  9299 epoch:  0 loss: 1.12234\n",
      "class_loss: 1.12234 \t mask_loss: 1.12234\n",
      "class_acc: 0.69063 \t mask_acc: 0.69063\n",
      "batch:  9359 epoch:  0 loss: 0.99647\n",
      "class_loss: 0.99647 \t mask_loss: 0.99647\n",
      "class_acc: 0.71458 \t mask_acc: 0.71458\n",
      "batch:  9419 epoch:  0 loss: 0.92598\n",
      "class_loss: 0.92598 \t mask_loss: 0.92598\n",
      "class_acc: 0.73646 \t mask_acc: 0.73646\n",
      "batch:  9479 epoch:  0 loss: 0.97032\n",
      "class_loss: 0.97032 \t mask_loss: 0.97032\n",
      "class_acc: 0.71979 \t mask_acc: 0.71979\n",
      "batch:  9539 epoch:  0 loss: 0.97660\n",
      "class_loss: 0.97660 \t mask_loss: 0.97660\n",
      "class_acc: 0.71979 \t mask_acc: 0.71979\n",
      "batch:  9599 epoch:  0 loss: 1.05230\n",
      "class_loss: 1.05230 \t mask_loss: 1.05230\n",
      "class_acc: 0.69063 \t mask_acc: 0.69063\n",
      "batch:  9659 epoch:  0 loss: 0.98720\n",
      "class_loss: 0.98720 \t mask_loss: 0.98720\n",
      "class_acc: 0.73438 \t mask_acc: 0.73438\n",
      "batch:  9719 epoch:  0 loss: 1.00204\n",
      "class_loss: 1.00204 \t mask_loss: 1.00204\n",
      "class_acc: 0.71146 \t mask_acc: 0.71146\n",
      "batch:  9779 epoch:  0 loss: 0.92902\n",
      "class_loss: 0.92902 \t mask_loss: 0.92902\n",
      "class_acc: 0.72813 \t mask_acc: 0.72813\n",
      "batch:  9839 epoch:  0 loss: 0.94397\n",
      "class_loss: 0.94397 \t mask_loss: 0.94397\n",
      "class_acc: 0.71979 \t mask_acc: 0.71979\n",
      "batch:  9899 epoch:  0 loss: 0.87314\n",
      "class_loss: 0.87314 \t mask_loss: 0.87314\n",
      "class_acc: 0.75000 \t mask_acc: 0.75000\n",
      "batch:  9959 epoch:  0 loss: 0.96181\n",
      "class_loss: 0.96181 \t mask_loss: 0.96181\n",
      "class_acc: 0.71979 \t mask_acc: 0.71979\n",
      "batch:  10019 epoch:  0 loss: 0.94940\n",
      "class_loss: 0.94940 \t mask_loss: 0.94940\n",
      "class_acc: 0.73854 \t mask_acc: 0.73854\n",
      "batch:  10079 epoch:  0 loss: 0.94715\n",
      "class_loss: 0.94715 \t mask_loss: 0.94715\n",
      "class_acc: 0.73438 \t mask_acc: 0.73438\n",
      "batch:  10139 epoch:  0 loss: 0.95338\n",
      "class_loss: 0.95338 \t mask_loss: 0.95338\n",
      "class_acc: 0.72188 \t mask_acc: 0.72188\n",
      "batch:  10199 epoch:  0 loss: 1.03323\n",
      "class_loss: 1.03323 \t mask_loss: 1.03323\n",
      "class_acc: 0.71042 \t mask_acc: 0.71042\n",
      "batch:  10259 epoch:  0 loss: 0.94004\n",
      "class_loss: 0.94004 \t mask_loss: 0.94004\n",
      "class_acc: 0.73229 \t mask_acc: 0.73229\n",
      "batch:  10319 epoch:  0 loss: 0.88626\n",
      "class_loss: 0.88626 \t mask_loss: 0.88626\n",
      "class_acc: 0.75417 \t mask_acc: 0.75417\n",
      "batch:  10379 epoch:  0 loss: 0.96762\n",
      "class_loss: 0.96762 \t mask_loss: 0.96762\n",
      "class_acc: 0.72083 \t mask_acc: 0.72083\n",
      "batch:  10439 epoch:  0 loss: 0.95539\n",
      "class_loss: 0.95539 \t mask_loss: 0.95539\n",
      "class_acc: 0.73333 \t mask_acc: 0.73333\n",
      "batch:  10499 epoch:  0 loss: 0.92750\n",
      "class_loss: 0.92750 \t mask_loss: 0.92750\n",
      "class_acc: 0.72500 \t mask_acc: 0.72500\n",
      "batch:  10559 epoch:  0 loss: 0.94382\n",
      "class_loss: 0.94382 \t mask_loss: 0.94382\n",
      "class_acc: 0.71354 \t mask_acc: 0.71354\n",
      "batch:  10619 epoch:  0 loss: 0.84850\n",
      "class_loss: 0.84850 \t mask_loss: 0.84850\n",
      "class_acc: 0.74479 \t mask_acc: 0.74479\n",
      "batch:  10679 epoch:  0 loss: 0.92577\n",
      "class_loss: 0.92577 \t mask_loss: 0.92577\n",
      "class_acc: 0.74375 \t mask_acc: 0.74375\n",
      "batch:  10739 epoch:  0 loss: 0.82944\n",
      "class_loss: 0.82944 \t mask_loss: 0.82944\n",
      "class_acc: 0.76875 \t mask_acc: 0.76875\n",
      "batch:  10799 epoch:  0 loss: 0.90060\n",
      "class_loss: 0.90060 \t mask_loss: 0.90060\n",
      "class_acc: 0.74271 \t mask_acc: 0.74271\n",
      "batch:  10859 epoch:  0 loss: 0.82384\n",
      "class_loss: 0.82384 \t mask_loss: 0.82384\n",
      "class_acc: 0.75208 \t mask_acc: 0.75208\n",
      "batch:  10919 epoch:  0 loss: 0.97545\n",
      "class_loss: 0.97545 \t mask_loss: 0.97545\n",
      "class_acc: 0.73333 \t mask_acc: 0.73333\n",
      "batch:  10979 epoch:  0 loss: 0.95629\n",
      "class_loss: 0.95629 \t mask_loss: 0.95629\n",
      "class_acc: 0.74271 \t mask_acc: 0.74271\n",
      "batch:  11039 epoch:  0 loss: 0.86616\n",
      "class_loss: 0.86616 \t mask_loss: 0.86616\n",
      "class_acc: 0.75000 \t mask_acc: 0.75000\n",
      "batch:  11099 epoch:  0 loss: 0.93121\n",
      "class_loss: 0.93121 \t mask_loss: 0.93121\n",
      "class_acc: 0.72396 \t mask_acc: 0.72396\n",
      "batch:  11159 epoch:  0 loss: 0.86971\n",
      "class_loss: 0.86971 \t mask_loss: 0.86971\n",
      "class_acc: 0.73125 \t mask_acc: 0.73125\n",
      "batch:  11219 epoch:  0 loss: 0.92656\n",
      "class_loss: 0.92656 \t mask_loss: 0.92656\n",
      "class_acc: 0.74167 \t mask_acc: 0.74167\n",
      "batch:  11279 epoch:  0 loss: 0.95264\n",
      "class_loss: 0.95264 \t mask_loss: 0.95264\n",
      "class_acc: 0.72396 \t mask_acc: 0.72396\n",
      "batch:  11339 epoch:  0 loss: 0.95121\n",
      "class_loss: 0.95121 \t mask_loss: 0.95121\n",
      "class_acc: 0.73333 \t mask_acc: 0.73333\n",
      "batch:  11399 epoch:  0 loss: 0.88672\n",
      "class_loss: 0.88672 \t mask_loss: 0.88672\n",
      "class_acc: 0.75104 \t mask_acc: 0.75104\n",
      "batch:  11459 epoch:  0 loss: 0.85625\n",
      "class_loss: 0.85625 \t mask_loss: 0.85625\n",
      "class_acc: 0.75729 \t mask_acc: 0.75729\n",
      "batch:  11519 epoch:  0 loss: 0.96811\n",
      "class_loss: 0.96811 \t mask_loss: 0.96811\n",
      "class_acc: 0.71979 \t mask_acc: 0.71979\n",
      "batch:  11579 epoch:  0 loss: 0.88618\n",
      "class_loss: 0.88618 \t mask_loss: 0.88618\n",
      "class_acc: 0.74167 \t mask_acc: 0.74167\n",
      "batch:  11639 epoch:  0 loss: 0.88634\n",
      "class_loss: 0.88634 \t mask_loss: 0.88634\n",
      "class_acc: 0.73854 \t mask_acc: 0.73854\n",
      "batch:  11699 epoch:  0 loss: 0.82251\n",
      "class_loss: 0.82251 \t mask_loss: 0.82251\n",
      "class_acc: 0.75833 \t mask_acc: 0.75833\n",
      "batch:  11759 epoch:  0 loss: 0.87966\n",
      "class_loss: 0.87966 \t mask_loss: 0.87966\n",
      "class_acc: 0.73854 \t mask_acc: 0.73854\n",
      "batch:  11819 epoch:  0 loss: 0.94119\n",
      "class_loss: 0.94119 \t mask_loss: 0.94119\n",
      "class_acc: 0.73750 \t mask_acc: 0.73750\n",
      "batch:  11879 epoch:  0 loss: 0.99736\n",
      "class_loss: 0.99736 \t mask_loss: 0.99736\n",
      "class_acc: 0.70937 \t mask_acc: 0.70937\n",
      "batch:  11939 epoch:  0 loss: 0.91129\n",
      "class_loss: 0.91129 \t mask_loss: 0.91129\n",
      "class_acc: 0.75938 \t mask_acc: 0.75938\n",
      "batch:  11999 epoch:  0 loss: 0.95834\n",
      "class_loss: 0.95834 \t mask_loss: 0.95834\n",
      "class_acc: 0.72292 \t mask_acc: 0.72292\n",
      "batch:  12059 epoch:  0 loss: 0.92299\n",
      "class_loss: 0.92299 \t mask_loss: 0.92299\n",
      "class_acc: 0.74479 \t mask_acc: 0.74479\n",
      "batch:  12119 epoch:  0 loss: 0.92435\n",
      "class_loss: 0.92435 \t mask_loss: 0.92435\n",
      "class_acc: 0.73750 \t mask_acc: 0.73750\n",
      "batch:  12179 epoch:  0 loss: 0.95493\n",
      "class_loss: 0.95493 \t mask_loss: 0.95493\n",
      "class_acc: 0.72813 \t mask_acc: 0.72813\n",
      "batch:  12239 epoch:  0 loss: 0.78666\n",
      "class_loss: 0.78666 \t mask_loss: 0.78666\n",
      "class_acc: 0.75833 \t mask_acc: 0.75833\n",
      "batch:  12299 epoch:  0 loss: 0.82322\n",
      "class_loss: 0.82322 \t mask_loss: 0.82322\n",
      "class_acc: 0.76146 \t mask_acc: 0.76146\n",
      "batch:  12359 epoch:  0 loss: 0.91191\n",
      "class_loss: 0.91191 \t mask_loss: 0.91191\n",
      "class_acc: 0.73021 \t mask_acc: 0.73021\n",
      "batch:  12419 epoch:  0 loss: 0.93916\n",
      "class_loss: 0.93916 \t mask_loss: 0.93916\n",
      "class_acc: 0.73333 \t mask_acc: 0.73333\n",
      "batch:  12479 epoch:  0 loss: 0.85527\n",
      "class_loss: 0.85527 \t mask_loss: 0.85527\n",
      "class_acc: 0.74479 \t mask_acc: 0.74479\n",
      "batch:  12539 epoch:  0 loss: 0.90093\n",
      "class_loss: 0.90093 \t mask_loss: 0.90093\n",
      "class_acc: 0.74375 \t mask_acc: 0.74375\n",
      "batch:  12599 epoch:  0 loss: 0.93006\n",
      "class_loss: 0.93006 \t mask_loss: 0.93006\n",
      "class_acc: 0.73229 \t mask_acc: 0.73229\n",
      "batch:  12659 epoch:  0 loss: 0.82696\n",
      "class_loss: 0.82696 \t mask_loss: 0.82696\n",
      "class_acc: 0.76042 \t mask_acc: 0.76042\n",
      "batch:  12719 epoch:  0 loss: 0.88369\n",
      "class_loss: 0.88369 \t mask_loss: 0.88369\n",
      "class_acc: 0.75625 \t mask_acc: 0.75625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch:  12779 epoch:  0 loss: 0.86598\n",
      "class_loss: 0.86598 \t mask_loss: 0.86598\n",
      "class_acc: 0.74375 \t mask_acc: 0.74375\n",
      "batch:  12839 epoch:  0 loss: 0.86029\n",
      "class_loss: 0.86029 \t mask_loss: 0.86029\n",
      "class_acc: 0.74167 \t mask_acc: 0.74167\n",
      "batch:  12899 epoch:  0 loss: 0.88388\n",
      "class_loss: 0.88388 \t mask_loss: 0.88388\n",
      "class_acc: 0.74792 \t mask_acc: 0.74792\n",
      "batch:  12959 epoch:  0 loss: 0.81716\n",
      "class_loss: 0.81716 \t mask_loss: 0.81716\n",
      "class_acc: 0.75313 \t mask_acc: 0.75313\n",
      "batch:  13019 epoch:  0 loss: 0.91430\n",
      "class_loss: 0.91430 \t mask_loss: 0.91430\n",
      "class_acc: 0.73229 \t mask_acc: 0.73229\n",
      "batch:  13079 epoch:  0 loss: 0.86214\n",
      "class_loss: 0.86214 \t mask_loss: 0.86214\n",
      "class_acc: 0.75208 \t mask_acc: 0.75208\n",
      "batch:  13139 epoch:  0 loss: 0.88663\n",
      "class_loss: 0.88663 \t mask_loss: 0.88663\n",
      "class_acc: 0.74167 \t mask_acc: 0.74167\n",
      "batch:  13199 epoch:  0 loss: 0.89000\n",
      "class_loss: 0.89000 \t mask_loss: 0.89000\n",
      "class_acc: 0.75000 \t mask_acc: 0.75000\n",
      "batch:  13259 epoch:  0 loss: 0.95774\n",
      "class_loss: 0.95774 \t mask_loss: 0.95774\n",
      "class_acc: 0.73646 \t mask_acc: 0.73646\n",
      "batch:  13319 epoch:  0 loss: 0.80041\n",
      "class_loss: 0.80041 \t mask_loss: 0.80041\n",
      "class_acc: 0.78229 \t mask_acc: 0.78229\n",
      "batch:  13379 epoch:  0 loss: 0.94294\n",
      "class_loss: 0.94294 \t mask_loss: 0.94294\n",
      "class_acc: 0.74271 \t mask_acc: 0.74271\n",
      "batch:  13439 epoch:  0 loss: 0.76622\n",
      "class_loss: 0.76622 \t mask_loss: 0.76622\n",
      "class_acc: 0.78854 \t mask_acc: 0.78854\n",
      "batch:  13499 epoch:  0 loss: 0.95682\n",
      "class_loss: 0.95682 \t mask_loss: 0.95682\n",
      "class_acc: 0.73750 \t mask_acc: 0.73750\n",
      "batch:  13559 epoch:  0 loss: 0.76271\n",
      "class_loss: 0.76271 \t mask_loss: 0.76271\n",
      "class_acc: 0.79063 \t mask_acc: 0.79063\n",
      "batch:  13619 epoch:  0 loss: 0.91704\n",
      "class_loss: 0.91704 \t mask_loss: 0.91704\n",
      "class_acc: 0.73646 \t mask_acc: 0.73646\n",
      "batch:  13679 epoch:  0 loss: 0.81810\n",
      "class_loss: 0.81810 \t mask_loss: 0.81810\n",
      "class_acc: 0.75833 \t mask_acc: 0.75833\n",
      "batch:  13739 epoch:  0 loss: 0.75850\n",
      "class_loss: 0.75850 \t mask_loss: 0.75850\n",
      "class_acc: 0.76875 \t mask_acc: 0.76875\n",
      "batch:  13799 epoch:  0 loss: 0.82506\n",
      "class_loss: 0.82506 \t mask_loss: 0.82506\n",
      "class_acc: 0.74271 \t mask_acc: 0.74271\n",
      "batch:  13859 epoch:  0 loss: 0.86704\n",
      "class_loss: 0.86704 \t mask_loss: 0.86704\n",
      "class_acc: 0.75104 \t mask_acc: 0.75104\n",
      "batch:  13919 epoch:  0 loss: 0.86413\n",
      "class_loss: 0.86413 \t mask_loss: 0.86413\n",
      "class_acc: 0.74479 \t mask_acc: 0.74479\n",
      "batch:  13979 epoch:  0 loss: 0.78991\n",
      "class_loss: 0.78991 \t mask_loss: 0.78991\n",
      "class_acc: 0.77708 \t mask_acc: 0.77708\n",
      "batch:  14039 epoch:  0 loss: 0.93811\n",
      "class_loss: 0.93811 \t mask_loss: 0.93811\n",
      "class_acc: 0.73646 \t mask_acc: 0.73646\n",
      "batch:  14099 epoch:  0 loss: 0.78886\n",
      "class_loss: 0.78886 \t mask_loss: 0.78886\n",
      "class_acc: 0.77292 \t mask_acc: 0.77292\n",
      "batch:  14159 epoch:  0 loss: 0.74775\n",
      "class_loss: 0.74775 \t mask_loss: 0.74775\n",
      "class_acc: 0.78646 \t mask_acc: 0.78646\n",
      "batch:  14219 epoch:  0 loss: 0.79730\n",
      "class_loss: 0.79730 \t mask_loss: 0.79730\n",
      "class_acc: 0.76458 \t mask_acc: 0.76458\n",
      "batch:  14279 epoch:  0 loss: 0.91488\n",
      "class_loss: 0.91488 \t mask_loss: 0.91488\n",
      "class_acc: 0.73229 \t mask_acc: 0.73229\n",
      "batch:  14339 epoch:  0 loss: 0.81087\n",
      "class_loss: 0.81087 \t mask_loss: 0.81087\n",
      "class_acc: 0.78438 \t mask_acc: 0.78438\n",
      "batch:  14399 epoch:  0 loss: 0.84350\n",
      "class_loss: 0.84350 \t mask_loss: 0.84350\n",
      "class_acc: 0.74479 \t mask_acc: 0.74479\n",
      "batch:  14459 epoch:  0 loss: 0.86062\n",
      "class_loss: 0.86062 \t mask_loss: 0.86062\n",
      "class_acc: 0.76562 \t mask_acc: 0.76562\n",
      "batch:  14519 epoch:  0 loss: 0.78095\n",
      "class_loss: 0.78095 \t mask_loss: 0.78095\n",
      "class_acc: 0.76562 \t mask_acc: 0.76562\n",
      "batch:  14579 epoch:  0 loss: 0.80808\n",
      "class_loss: 0.80808 \t mask_loss: 0.80808\n",
      "class_acc: 0.77292 \t mask_acc: 0.77292\n",
      "batch:  14639 epoch:  0 loss: 0.91658\n",
      "class_loss: 0.91658 \t mask_loss: 0.91658\n",
      "class_acc: 0.75938 \t mask_acc: 0.75938\n",
      "batch:  14699 epoch:  0 loss: 0.82721\n",
      "class_loss: 0.82721 \t mask_loss: 0.82721\n",
      "class_acc: 0.75521 \t mask_acc: 0.75521\n",
      "batch:  14759 epoch:  0 loss: 0.85450\n",
      "class_loss: 0.85450 \t mask_loss: 0.85450\n",
      "class_acc: 0.76875 \t mask_acc: 0.76875\n",
      "batch:  14819 epoch:  0 loss: 0.82601\n",
      "class_loss: 0.82601 \t mask_loss: 0.82601\n",
      "class_acc: 0.75521 \t mask_acc: 0.75521\n",
      "batch:  14879 epoch:  0 loss: 0.77623\n",
      "class_loss: 0.77623 \t mask_loss: 0.77623\n",
      "class_acc: 0.76979 \t mask_acc: 0.76979\n",
      "batch:  14939 epoch:  0 loss: 0.88514\n",
      "class_loss: 0.88514 \t mask_loss: 0.88514\n",
      "class_acc: 0.74792 \t mask_acc: 0.74792\n",
      "batch:  14999 epoch:  0 loss: 0.83153\n",
      "class_loss: 0.83153 \t mask_loss: 0.83153\n",
      "class_acc: 0.77187 \t mask_acc: 0.77187\n",
      "batch:  15059 epoch:  0 loss: 0.82955\n",
      "class_loss: 0.82955 \t mask_loss: 0.82955\n",
      "class_acc: 0.77500 \t mask_acc: 0.77500\n",
      "batch:  15119 epoch:  0 loss: 0.86151\n",
      "class_loss: 0.86151 \t mask_loss: 0.86151\n",
      "class_acc: 0.77083 \t mask_acc: 0.77083\n",
      "batch:  15179 epoch:  0 loss: 0.83282\n",
      "class_loss: 0.83282 \t mask_loss: 0.83282\n",
      "class_acc: 0.75833 \t mask_acc: 0.75833\n",
      "batch:  15239 epoch:  0 loss: 0.89893\n",
      "class_loss: 0.89893 \t mask_loss: 0.89893\n",
      "class_acc: 0.75313 \t mask_acc: 0.75313\n",
      "batch:  15299 epoch:  0 loss: 0.80155\n",
      "class_loss: 0.80155 \t mask_loss: 0.80155\n",
      "class_acc: 0.76458 \t mask_acc: 0.76458\n",
      "batch:  15359 epoch:  0 loss: 0.81788\n",
      "class_loss: 0.81788 \t mask_loss: 0.81788\n",
      "class_acc: 0.76354 \t mask_acc: 0.76354\n",
      "batch:  15419 epoch:  0 loss: 0.91015\n",
      "class_loss: 0.91015 \t mask_loss: 0.91015\n",
      "class_acc: 0.73750 \t mask_acc: 0.73750\n",
      "batch:  15479 epoch:  0 loss: 0.87029\n",
      "class_loss: 0.87029 \t mask_loss: 0.87029\n",
      "class_acc: 0.74792 \t mask_acc: 0.74792\n",
      "batch:  15539 epoch:  0 loss: 0.84308\n",
      "class_loss: 0.84308 \t mask_loss: 0.84308\n",
      "class_acc: 0.76979 \t mask_acc: 0.76979\n",
      "batch:  15599 epoch:  0 loss: 0.85879\n",
      "class_loss: 0.85879 \t mask_loss: 0.85879\n",
      "class_acc: 0.75521 \t mask_acc: 0.75521\n",
      "batch:  15659 epoch:  0 loss: 0.85082\n",
      "class_loss: 0.85082 \t mask_loss: 0.85082\n",
      "class_acc: 0.75938 \t mask_acc: 0.75938\n",
      "batch:  15719 epoch:  0 loss: 0.71670\n",
      "class_loss: 0.71670 \t mask_loss: 0.71670\n",
      "class_acc: 0.78333 \t mask_acc: 0.78333\n",
      "batch:  15779 epoch:  0 loss: 0.83777\n",
      "class_loss: 0.83777 \t mask_loss: 0.83777\n",
      "class_acc: 0.75729 \t mask_acc: 0.75729\n",
      "batch:  15839 epoch:  0 loss: 0.80398\n",
      "class_loss: 0.80398 \t mask_loss: 0.80398\n",
      "class_acc: 0.75833 \t mask_acc: 0.75833\n",
      "batch:  15899 epoch:  0 loss: 0.90169\n",
      "class_loss: 0.90169 \t mask_loss: 0.90169\n",
      "class_acc: 0.73333 \t mask_acc: 0.73333\n",
      "batch:  15959 epoch:  0 loss: 0.88013\n",
      "class_loss: 0.88013 \t mask_loss: 0.88013\n",
      "class_acc: 0.76042 \t mask_acc: 0.76042\n",
      "batch:  16019 epoch:  0 loss: 0.87394\n",
      "class_loss: 0.87394 \t mask_loss: 0.87394\n",
      "class_acc: 0.74792 \t mask_acc: 0.74792\n",
      "batch:  16079 epoch:  0 loss: 0.79954\n",
      "class_loss: 0.79954 \t mask_loss: 0.79954\n",
      "class_acc: 0.76771 \t mask_acc: 0.76771\n",
      "batch:  16139 epoch:  0 loss: 0.77149\n",
      "class_loss: 0.77149 \t mask_loss: 0.77149\n",
      "class_acc: 0.78854 \t mask_acc: 0.78854\n",
      "batch:  16199 epoch:  0 loss: 0.81911\n",
      "class_loss: 0.81911 \t mask_loss: 0.81911\n",
      "class_acc: 0.76458 \t mask_acc: 0.76458\n",
      "batch:  16259 epoch:  0 loss: 0.79458\n",
      "class_loss: 0.79458 \t mask_loss: 0.79458\n",
      "class_acc: 0.76875 \t mask_acc: 0.76875\n",
      "batch:  16319 epoch:  0 loss: 0.81572\n",
      "class_loss: 0.81572 \t mask_loss: 0.81572\n",
      "class_acc: 0.76042 \t mask_acc: 0.76042\n",
      "batch:  16379 epoch:  0 loss: 0.80806\n",
      "class_loss: 0.80806 \t mask_loss: 0.80806\n",
      "class_acc: 0.77708 \t mask_acc: 0.77708\n",
      "batch:  16439 epoch:  0 loss: 0.78462\n",
      "class_loss: 0.78462 \t mask_loss: 0.78462\n",
      "class_acc: 0.76250 \t mask_acc: 0.76250\n",
      "batch:  16499 epoch:  0 loss: 0.75912\n",
      "class_loss: 0.75912 \t mask_loss: 0.75912\n",
      "class_acc: 0.78333 \t mask_acc: 0.78333\n",
      "batch:  16559 epoch:  0 loss: 0.74412\n",
      "class_loss: 0.74412 \t mask_loss: 0.74412\n",
      "class_acc: 0.78750 \t mask_acc: 0.78750\n",
      "batch:  16619 epoch:  0 loss: 0.80508\n",
      "class_loss: 0.80508 \t mask_loss: 0.80508\n",
      "class_acc: 0.78021 \t mask_acc: 0.78021\n",
      "batch:  16679 epoch:  0 loss: 0.87795\n",
      "class_loss: 0.87795 \t mask_loss: 0.87795\n",
      "class_acc: 0.74271 \t mask_acc: 0.74271\n",
      "batch:  16739 epoch:  0 loss: 0.77349\n",
      "class_loss: 0.77349 \t mask_loss: 0.77349\n",
      "class_acc: 0.77292 \t mask_acc: 0.77292\n",
      "batch:  16799 epoch:  0 loss: 0.78468\n",
      "class_loss: 0.78468 \t mask_loss: 0.78468\n",
      "class_acc: 0.77396 \t mask_acc: 0.77396\n",
      "batch:  16859 epoch:  0 loss: 0.82348\n",
      "class_loss: 0.82348 \t mask_loss: 0.82348\n",
      "class_acc: 0.75521 \t mask_acc: 0.75521\n",
      "batch:  16919 epoch:  0 loss: 0.89198\n",
      "class_loss: 0.89198 \t mask_loss: 0.89198\n",
      "class_acc: 0.75313 \t mask_acc: 0.75313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch:  16979 epoch:  0 loss: 0.78030\n",
      "class_loss: 0.78030 \t mask_loss: 0.78030\n",
      "class_acc: 0.77187 \t mask_acc: 0.77187\n",
      "batch:  17039 epoch:  0 loss: 0.79939\n",
      "class_loss: 0.79939 \t mask_loss: 0.79939\n",
      "class_acc: 0.77083 \t mask_acc: 0.77083\n"
     ]
    }
   ],
   "source": [
    "# torch.set_printoptions(threshold=10**6)\n",
    "iters_per_checkpoint = 60\n",
    "for epoch in range(10000):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    loss1,loss2 = 0.0,0.0\n",
    "    acc1,acc2 = 0.0,0.0\n",
    "    for i,data in enumerate(train_loader,0):\n",
    "        batch_images,batch_impulses,batch_gt_responses,batch_bboxes,batch_one_hot = data\n",
    "        batch_images = batch_images.cuda(non_blocking=True) \n",
    "        batch_impulses = batch_impulses.cuda(non_blocking=True) \n",
    "#         batch_gt_responses = batch_gt_responses.cuda(non_blocking=True) \n",
    "#         batch_bboxes = batch_bboxes.cuda(non_blocking=True) \n",
    "        batch_one_hot = batch_one_hot.cuda(non_blocking=True) \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        pred_class,pred_masks = net([batch_images,batch_impulses])\n",
    "        # we are giving no weighting for classes...\n",
    "        class_loss,mask_loss = model_lib.multi_mask_loss_criterion(pred_class,batch_one_hot,pred_masks,batch_gt_responses,batch_bboxes)\n",
    "        class_acc, mask_acc = model_lib.accuracy(pred_class,batch_one_hot,pred_masks[1],batch_gt_responses)\n",
    "        loss = class_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item(); loss1 += class_loss.item(); loss2 += mask_loss.item()\n",
    "        acc1 += class_acc.item(); acc2 += mask_acc.item()\n",
    "        if i % iters_per_checkpoint == iters_per_checkpoint-1:\n",
    "#             scheduler.step((loss1+loss2)/iters_per_checkpoint)\n",
    "            print(\"batch: \",i,\"epoch: \",epoch, \"loss: %0.5f\" % (running_loss/iters_per_checkpoint))\n",
    "            print(\"class_loss: %0.5f \\t mask_loss: %0.5f\"%(loss1/iters_per_checkpoint,loss2/iters_per_checkpoint))\n",
    "            print(\"class_acc: %0.5f \\t mask_acc: %0.5f\"%(acc1/iters_per_checkpoint,acc2/iters_per_checkpoint))\n",
    "#             torch.save(net.state_dict(),model_dir+(\"model_mask_vgg_%d_%d.pt\")%(2,2))\n",
    "            torch.save(net.state_dict(),model_dir+(\"bbox_02.pt\"))\n",
    "            running_loss = 0.0; loss1 = 0.0; loss2 = 0.0\n",
    "            acc1 = 0.0; acc2 = 0.0\n",
    "    # print(\"batch: %d time:%0.3f sec\" %(i, end-start)); print(loss.item())\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:re]",
   "language": "python",
   "name": "conda-env-re-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
