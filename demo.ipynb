{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To infer at test time. \n",
    "# Take impulse as input from user \n",
    "# and predict object corresponding to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_lib\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', '.*output shape of zoom.*')\n",
    "import pickle\n",
    "import importlib\n",
    "importlib.reload(model_lib)\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config to train\n",
    "# TODO: check Config is correct\n",
    "class ProposalConfig():\n",
    "    NAME = \"InSegm\"\n",
    "    GPU_COUNT = 1\n",
    "    # online training\n",
    "    IMAGES_PER_GPU = 1\n",
    "    STEPS_PER_EPOCH = 100\n",
    "    NUM_WORKERS = 1\n",
    "    PIN_MEMORY = True\n",
    "    DATA_ORDER = \"cw_ins\"\n",
    "    VALIDATION_STEPS = 20\n",
    "    # including gt\n",
    "    NUM_CLASSES = 81\n",
    "    \n",
    "    # only flips\n",
    "    MEAN_PIXEL = np.array([0.485, 0.456, 0.406],dtype=np.float32).reshape(1,1,-1)\n",
    "    STD_PIXEL = np.array([0.229, 0.224, 0.225],dtype=np.float32).reshape(1,1,-1)\n",
    "    CLASS_NAMES = [\n",
    "        'BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "        'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign',\n",
    "        'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep',\n",
    "        'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella',\n",
    "        'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard',\n",
    "        'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "        'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork',\n",
    "        'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange',\n",
    "        'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair',\n",
    "        'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv',\n",
    "        'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave',\n",
    "        'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase',\n",
    "        'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "    ]\n",
    "    WIDTH = 224\n",
    "    HEIGHT = 224\n",
    "    CROP_SIZE = 224\n",
    "    def __init__(self):\n",
    "        self.BATCH_SIZE = self.IMAGES_PER_GPU * self.GPU_COUNT\n",
    "        self.IMAGE_SHAPE = (self.WIDTH, self.HEIGHT,3)\n",
    "\n",
    "    def display(self):\n",
    "        \"\"\"Display Configuration values.\"\"\"\n",
    "        print(\"\\nConfigurations:\")\n",
    "        for a in dir(self):\n",
    "            if not a.startswith(\"__\") and not callable(getattr(self, a)):\n",
    "                print(\"{:30} {}\".format(a, getattr(self, a)))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"/media/Data1/interns/aravind/test2017/\"\n",
    "model_dir = \"./models/\"\n",
    "config = ProposalConfig()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "net = model_lib.MultiHGModel()\n",
    "\n",
    "pretrained_dict = torch.load(model_dir+\"stage_wise_04.pt\")\n",
    "net_dict = net.state_dict()\n",
    "\n",
    "\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in net_dict}\n",
    "net_dict.update(pretrained_dict) \n",
    "net.load_state_dict(net_dict)\n",
    "\n",
    "# net.vgg.load_state_dict(torch.load(model_dir+\"model_vgg_class_only.pt\").vgg)\n",
    "# net.classifier.load_state_dict(torch.load(model_dir+\"model_vgg_class_only.pt\").classifier)\n",
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_and_quit(np_images):\n",
    "    mode = {2:'L',3:'RGB'}\n",
    "    objs = []\n",
    "    for img in np_images:\n",
    "        f = Image.fromarray(img.astype(np.uint8),mode[img.ndim]).resize((224,224),Image.BILINEAR)\n",
    "        objs.append(f)\n",
    "        f.show()        \n",
    "    time.sleep\n",
    "    [f.close() for f in objs]\n",
    "def detect_on_loc(event,img_obj):\n",
    "    q, p = event.x, event.y\n",
    "    impulse = np.zeros((4,) + img_obj.size).astype(np.float32)\n",
    "    w,h = img_obj.size\n",
    "    l = 8\n",
    "    n = 4\n",
    "    for i in range(4):\n",
    "        L = (l // 2) * (3**i)\n",
    "        impulse[i][max(p - L, 0):min(p + L, w), max(q - L, 0):min(q + L, h)] = 1\n",
    "    with torch.no_grad():\n",
    "        image = np.array(img_obj).astype(np.float32)\n",
    "        batch_images = image/256\n",
    "        batch_images -= config.MEAN_PIXEL\n",
    "        batch_images /= config.STD_PIXEL\n",
    "\n",
    "        batch_images = torch.from_numpy(np.moveaxis(np.expand_dims(batch_images,0),-1,1)).cuda()\n",
    "        batch_impulses = torch.from_numpy(np.expand_dims(impulse,0)).cuda()\n",
    "\n",
    "        pred_class,pred_masks = net([batch_images,batch_impulses])\n",
    "\n",
    "        pred_class = F.softmax(pred_class,dim=-1).squeeze()\n",
    "        maxs, indices = torch.topk(pred_class,5,-1)\n",
    "\n",
    "        pred_mask = pred_masks[1].squeeze()\n",
    "        pred_mask = F.sigmoid(pred_mask)\n",
    "        pred_mask = F.threshold(pred_mask,0.5,0)\n",
    "        pred_mask = pred_mask.squeeze().cpu().numpy()*255\n",
    "#         Image.fromarray(pred_mask.astype(np.uint8),\"L\").convert(\"RGB\").show()\n",
    "\n",
    "        pred_mask = pred_masks[1].squeeze()\n",
    "        pred_mask = F.sigmoid(pred_mask)\n",
    "#         pred_mask = F.threshold(pred_mask,0.7,0)\n",
    "        pred_mask = pred_mask.squeeze().cpu().numpy()*255\n",
    "#         Image.fromarray(pred_mask.astype(np.uint8),\"L\").convert(\"RGB\").show()\n",
    "\n",
    "        for i in range(5):\n",
    "            print(maxs[i],indices[i],config.CLASS_NAMES[int(indices[i])])\n",
    "        print(\"=====\")\n",
    "        show_and_quit([pred_mask])\n",
    "\n",
    "\n",
    "def get_image(image_path):\n",
    "    thumbnail_shape = (224,224)\n",
    "    z = Image.new(\"RGB\", thumbnail_shape, \"black\")\n",
    "    image_obj = Image.open(image_path).convert(\"RGB\")\n",
    "    image_obj.thumbnail(thumbnail_shape, Image.ANTIALIAS)\n",
    "    (w, h) = image_obj.size\n",
    "    z.paste(image_obj, ((thumbnail_shape[0] - w) // 2, (thumbnail_shape[1] - h) // 2))\n",
    "    return z\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/Data1/interns/aravind/test2017/000000223615.jpg\n",
      "tensor(0.9511, device='cuda:0') tensor(50, device='cuda:0') orange\n",
      "tensor(1.00000e-02 *\n",
      "       4.6301, device='cuda:0') tensor(48, device='cuda:0') apple\n",
      "tensor(1.00000e-03 *\n",
      "       2.2584, device='cuda:0') tensor(47, device='cuda:0') banana\n",
      "tensor(1.00000e-04 *\n",
      "       1.8773, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(1.00000e-05 *\n",
      "       4.2083, device='cuda:0') tensor(55, device='cuda:0') donut\n",
      "=====\n",
      "tensor(0.6125, device='cuda:0') tensor(50, device='cuda:0') orange\n",
      "tensor(0.3594, device='cuda:0') tensor(48, device='cuda:0') apple\n",
      "tensor(1.00000e-02 *\n",
      "       2.3295, device='cuda:0') tensor(47, device='cuda:0') banana\n",
      "tensor(1.00000e-04 *\n",
      "       7.4261, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(1.00000e-04 *\n",
      "       6.7142, device='cuda:0') tensor(55, device='cuda:0') donut\n",
      "=====\n",
      "tensor(0.8990, device='cuda:0') tensor(47, device='cuda:0') banana\n",
      "tensor(1.00000e-02 *\n",
      "       6.0704, device='cuda:0') tensor(48, device='cuda:0') apple\n",
      "tensor(1.00000e-02 *\n",
      "       3.3776, device='cuda:0') tensor(50, device='cuda:0') orange\n",
      "tensor(1.00000e-03 *\n",
      "       1.3145, device='cuda:0') tensor(40, device='cuda:0') bottle\n",
      "tensor(1.00000e-04 *\n",
      "       9.4662, device='cuda:0') tensor(46, device='cuda:0') bowl\n",
      "=====\n",
      "tensor(0.7647, device='cuda:0') tensor(47, device='cuda:0') banana\n",
      "tensor(0.1238, device='cuda:0') tensor(50, device='cuda:0') orange\n",
      "tensor(0.1067, device='cuda:0') tensor(48, device='cuda:0') apple\n",
      "tensor(1.00000e-03 *\n",
      "       1.2819, device='cuda:0') tensor(46, device='cuda:0') bowl\n",
      "tensor(1.00000e-04 *\n",
      "       5.6636, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "=====\n",
      "tensor(0.5166, device='cuda:0') tensor(47, device='cuda:0') banana\n",
      "tensor(0.2629, device='cuda:0') tensor(50, device='cuda:0') orange\n",
      "tensor(0.2033, device='cuda:0') tensor(48, device='cuda:0') apple\n",
      "tensor(1.00000e-03 *\n",
      "       4.1103, device='cuda:0') tensor(46, device='cuda:0') bowl\n",
      "tensor(1.00000e-03 *\n",
      "       1.7844, device='cuda:0') tensor(40, device='cuda:0') bottle\n",
      "=====\n",
      "tensor(0.5129, device='cuda:0') tensor(47, device='cuda:0') banana\n",
      "tensor(0.2619, device='cuda:0') tensor(50, device='cuda:0') orange\n",
      "tensor(0.2086, device='cuda:0') tensor(48, device='cuda:0') apple\n",
      "tensor(1.00000e-03 *\n",
      "       3.9830, device='cuda:0') tensor(46, device='cuda:0') bowl\n",
      "tensor(1.00000e-03 *\n",
      "       1.7167, device='cuda:0') tensor(40, device='cuda:0') bottle\n",
      "=====\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from PIL import ImageTk, Image\n",
    "image_path = image_dir+random.choice(os.listdir(image_dir))\n",
    "print(image_path)\n",
    "#This creates the main window of an application\n",
    "window = tk.Tk()\n",
    "window.title(\"Join\")\n",
    "window.geometry(\"224x224\")\n",
    "window.configure(background='grey')\n",
    "\n",
    "#Creates a Tkinter-compatible photo image, which can be used everywhere Tkinter expects an image object.\n",
    "img = ImageTk.PhotoImage(get_image(image_path))\n",
    "\n",
    "#The Label widget is a standard Tkinter widget used to display a text or image on the screen.\n",
    "panel = tk.Label(window, image = img)\n",
    "\n",
    "#The Pack geometry manager packs widgets in rows or columns.\n",
    "panel.pack(side = \"bottom\", fill = \"both\", expand = \"yes\")\n",
    "\n",
    "#Bind motion to motion function\n",
    "window.bind(\"<Button-1>\", lambda event, arg=get_image(image_path) : detect_on_loc(event, arg))\n",
    "\n",
    "#Start the GUI\n",
    "window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:re]",
   "language": "python",
   "name": "conda-env-re-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
